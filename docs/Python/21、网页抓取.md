# 21 网页抓取
### 什么是网页抓取
互联网充满了大量的数据，这些数据可以用于不同的目的。要收集这些数据，我们需要知道如何从网站上抓取数据。
网页抓取是从网站提取和收集数据，并将其存储在本地机器或数据库中的过程。
在本节中，我们将使用beautifulsoup和requests包来抓取数据。我们使用的是beautifulsoup 4版本。
要开始抓取网站，你需要_requests_、_beautifoulSoup4_和一个_网站_。

```sh
pip install requests
pip install beautifulsoup4
```

要从网站抓取数据，需要基本了解HTML标签和CSS选择器。我们使用HTML标签、类或/和ID来定位网站上的内容。
让我们导入requests和BeautifulSoup模块：

```py
import requests
from bs4 import BeautifulSoup
```

让我们声明一个url变量，用于我们要抓取的网站。

```py
import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/'
# 让我们使用requests的get方法从url获取数据
response = requests.get(url)
# 检查状态
status = response.status_code
print(status) # 200表示获取成功
```

使用beautifulSoup解析页面内容：

```py
import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/'
response = requests.get(url)
content = response.content # 我们从网站获取所有内容
soup = BeautifulSoup(content, 'html.parser') # beautiful soup将给我们一个解析的机会
print(soup.title) # <title>UCI Machine Learning Repository: Data Sets</title>
print(soup.title.get_text()) # UCI Machine Learning Repository: Data Sets
print(soup.body) # 给出网站上的整个页面
print(response.status_code)

tables = soup.find_all('h1', {'color':'hsl(var(--p) / var(--tw-text-opacity, 1));'})
# find_all: 在页面上寻找所有属性 cellpadding 等于 3 的 <table> 标签。
# tables[0]: 因为符合条件的表格可能有多个，结果是一个列表，我们从中提取数据，所以代码取了搜索结果中的第一个（索引为 0）。
table = tables[0]
print(table)
# for td in table.find('tr').find_all('td'):
#     print(td.text)
```

## 1. 问题与解决方案

| **遇到的问题**               | **错误原因分析**                                             | **解决方案**                                                 |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **找不到元素 (空列表 `[]`)** | 使用了不存在的属性定位（如 `margin: '0'`），或网页版本更新导致旧属性失效。 | 在浏览器按 **F12** 查看最新 HTML 结构，优先使用 `id` 或 `class` 定位。 |
| **`KeyError: 0`**            | **对象类型混淆**：对 `find()` 返回的单体标签对象使用了列表索引 `[0]`。 | `find()` 直接使用；`find_all()` 返回列表，才需要用 `[0]`。   |
| **`DeprecationWarning`**     | 使用了过时的方法名 `findAll`（驼峰命名法）。                 | 统一改用规范的下划线命名法：**`find_all()`**。               |

------

## 2. 关键技术点深入解析

### Ⅰ. 定位属性

- CSS 样式（如 `margin`, `padding`, `color`）不可以直接作为 BeautifulSoup 的属性查找。
- BeautifulSoup 默认只查找 **HTML 标签属性**（如 `class`, `id`, `href`, `src`）。
- `soup.find('h1', class_='text-lg')` —— 匹配 `<h1 class="text-lg">`。

### Ⅱ. `find()` 与 `find_all()` 的区别

```python
# find_all 返回的是(List)
apples = soup.find_all('h1')
first_apple = apples[0] # 正确

# find 返回的是(Tag Object)
one_apple = soup.find('h1')
text = one_apple.text # 正确
# text = one_apple[0] # 错误！
```

------

## 3. 现代爬虫建议

1. **处理 Class 关键字**：由于 `class` 是 Python 的保留关键字，在 BeautifulSoup 中必须写成 **`class_`**。

   - `soup.find('div', class_='container')`

2. **防止请求被封**：现代网站通常会检查访问者身份。建议加上 `headers` 伪装成浏览器：

   ```python
   headers = {'User-Agent': 'Mozilla/5.0'}
   response = requests.get(url, headers=headers)
   ```

3. **动态内容意识**：如果你发现 `print(soup.body)` 里的内容和你浏览器里看到的不一样，说明网页可能使用了 JavaScript 动态渲染，这时候单纯用 `requests` 可能抓不到数据。